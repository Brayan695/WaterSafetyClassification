{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78183e7d",
   "metadata": {},
   "source": [
    "# Data Modeling Assignment\n",
    "### Brayan Gutierrez, Katie To, Jericka Ledezma\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e0056",
   "metadata": {},
   "source": [
    "## Logistic Regression Model\n",
    "### Created by: Katie To\n",
    "referenced: https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8, \n",
    "https://towardsdatascience.com/logistic-regression-model-tuning-with-scikit-learn-part-1-425142e01af5\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269de8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c6577f",
   "metadata": {},
   "source": [
    "### Data Reading and Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Dataset\n",
    "ground_water = pd.read_csv(\"ground_water_quality_2022_post.csv\")\n",
    "ground_water_df = pd.DataFrame(ground_water)\n",
    "ground_water_df = ground_water_df.dropna()\n",
    "\n",
    "ground_water_df = ground_water_df.rename(columns = {'NO3 ': 'NO3'})\n",
    "ground_water_df = ground_water_df.rename(columns = {'RSC  meq  / L': 'RSC'})\n",
    "numeric = ground_water_df.select_dtypes(include=['number']).columns\n",
    "nonnumeric = ground_water_df.select_dtypes(exclude=['number']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb645f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Treatment\n",
    "\n",
    "for num in numeric:\n",
    "    Q1 = ground_water_df[num].quantile(0.25)\n",
    "    Q3 = ground_water_df[num].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    whisker_width = 1.5\n",
    "    lower_whisker = Q1 -(whisker_width*IQR)\n",
    "    upper_whisker = Q3 + (whisker_width*IQR)\n",
    "    ground_water_df[num]=np.where(ground_water_df[num]>upper_whisker,upper_whisker,np.where(ground_water_df[num]<lower_whisker,lower_whisker,ground_water_df[num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35666fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing Data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(ground_water_df[numeric])\n",
    "\n",
    "ground_water_df[numeric] = scaled_data\n",
    "\n",
    "ground_water_df[numeric].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c344591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Chosen Feature to Dataframe\n",
    "working_gw_df = ground_water_df[['RSC', 'SAR', 'Na', 'E.C', 'TDS', 'HCO3', 'pH', 'mandal', 'village', 'Classification.1']]\n",
    "working_gw_df = working_gw_df.replace('MR', 'U.S.')\n",
    "\n",
    "# Changing the Classification.1 to Numeric Valyes (P.S. = 0, U.S. = 1)\n",
    "le = LabelEncoder()\n",
    "working_gw_df['Classification.1']= le.fit_transform(working_gw_df['Classification.1']) \n",
    "\n",
    "# One-hot encode 'mandal' and 'village' columns separately\n",
    "mandal_dummies = pd.get_dummies(working_gw_df['mandal'], prefix='mandal')\n",
    "village_dummies = pd.get_dummies(working_gw_df['village'], prefix='village')\n",
    "\n",
    "# Concatenate the encoded columns with the original DataFrame\n",
    "working_gw_df_encoded = pd.concat([working_gw_df.drop(['mandal', 'village'], axis=1), mandal_dummies, village_dummies], axis=1)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "working_gw_df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac18893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "X = working_gw_df_encoded.drop(['Classification.1'], axis = 1)\n",
    "y = working_gw_df_encoded['Classification.1']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)\n",
    "\n",
    "sm = SMOTE(random_state = 2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6711e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter finetuning with grid search\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "y_pred_train = logreg.predict(X_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e212447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Test\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print('Accuracy of Logistic Regression classifier: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test, labels=logreg.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['P.S.', 'U.S.'])\n",
    "disp.plot().figure_.savefig('LOG_CM.png')\n",
    "correct = cm[0][0] + cm[1][1]\n",
    "incorrect = cm[0][1] + cm [1][0]\n",
    "print('Correctly Classified:', correct)\n",
    "print('Incorrectly Classified:', incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2926d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(classification_report(y_train_res, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6798dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca64d42",
   "metadata": {},
   "source": [
    "## Decision Tree Model\n",
    "### Created by: Jericka Ledezma\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict, StratifiedKFold, train_test_split\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3952a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_water = pd.read_csv(\"ground_water_quality_2022_post.csv\")\n",
    "ground_water_df = pd.DataFrame(ground_water)\n",
    "ground_water_df = ground_water_df.dropna()\n",
    "ground_water_df['Classification.1'] = ground_water_df['Classification.1'].replace('MR', 'U.S.')\n",
    "print(ground_water_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85341c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_water_df['pH'] = pd.to_numeric(ground_water_df['pH'], errors='coerce')\n",
    "ground_water_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20539051",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_water_df = ground_water_df.rename(columns = {'NO3 ': 'NO3'})\n",
    "ground_water_df = ground_water_df.rename(columns = {'RSC  meq  / L': 'RSC'})\n",
    "numeric = ground_water_df.select_dtypes(include=['number']).columns\n",
    "nonnumeric = ground_water_df.select_dtypes(exclude=['number']).columns\n",
    "cv = StratifiedKFold\n",
    "ground_water_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "\n",
    "feature_cols = ['RSC', 'SAR', 'T.H', 'Ca', 'Na', 'Mg', 'HCO3', 'mandal', 'village', 'E.C', 'TDS']# , 'RSC meq / L' , 'NO3' */\n",
    "X = ground_water_df[feature_cols] # Features\n",
    "y = ground_water_df['Classification.1'] # Target variable (could be 'Classification' or 'Classification.1')\n",
    "mandal_dummies = pd.get_dummies(X['mandal'], prefix='mandal')\n",
    "village_dummies = pd.get_dummies(X['village'], prefix='village')\n",
    "\n",
    "# Perform one-hot encoding using get_dummies() on the 'village' and 'mandal' columns\n",
    "#X_encoded = pd.get_dummies(X, columns=['village', 'mandal'], drop_first=True)  # Encoding 'village' and 'mandal' columns and dropping the original columns\n",
    "\n",
    "# Drop the original 'village' and 'mandal' columns from X_encoded\n",
    "working_gw_df_encoded = pd.concat([X.drop(['mandal', 'village'], axis=1), mandal_dummies, village_dummies], axis=1)\n",
    "\n",
    "X = working_gw_df_encoded\n",
    "\n",
    "working_gw_df_encoded.head()\n",
    "# Split dataset into training set and test set\n",
    "#you get to use all data to train model\n",
    "#check out to use kfold, use accuracy for attribute scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfebf4cd",
   "metadata": {},
   "source": [
    "### Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37707f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in numeric:\n",
    "    Q1 = ground_water_df[num].quantile(0.25)\n",
    "    Q3 = ground_water_df[num].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    whisker_width = 1.5\n",
    "    lower_whisker = Q1 -(whisker_width*IQR)\n",
    "    upper_whisker = Q3 + (whisker_width*IQR)\n",
    "    ground_water_df[num]=np.where(ground_water_df[num]>upper_whisker,upper_whisker,np.where(ground_water_df[num]<lower_whisker,lower_whisker,ground_water_df[num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(ground_water_df)\n",
    "\n",
    "for col in ground_water_df.columns:\n",
    "    cnts = ground_water_df[col].value_counts(dropna=False)\n",
    "    top_pct = (cnts/num_rows).iloc[0]\n",
    "    \n",
    "    if top_pct > 0.999:\n",
    "        print('{0}: {1:.2f}%'.format(col, top_pct*100))\n",
    "        print(cnts)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134261bc",
   "metadata": {},
   "source": [
    "### Decision Tree Fitting, Cross Validation, and Evaluation Metric #1 (Confusion Matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X =  working_gw_df_encoded\n",
    "y = ground_water_df['Classification.1']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "#this is where you specify the depth (change based on chart given in document [3,7,11,15])\n",
    "clf = DecisionTreeClassifier(max_depth = 15)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "# Create Decision Tree classifer object\n",
    "#this is where you specify the depth (change based on chart given in document [3,7,11,15])\n",
    "tree_depth = [3,7,11,15]\n",
    "exp_matrix =[[],[],[]]\n",
    "for i in tree_depth:\n",
    "    clf = DecisionTreeClassifier(max_depth = i)\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    accuracy = cross_val_score(clf, X, y, scoring='accuracy', cv = 5)\n",
    "    # precision = cross_val_score(clf, X, y, scoring='precision', cv = 5)\n",
    "    # recall = cross_val_score(clf, X, y, scoring='recall', cv = 5)\n",
    "    print(\"Depth for Training: \",i)\n",
    "    print(\"Accuracy for Training:\",accuracy.mean() * 100)\n",
    "    # print(\"Precision:\",precision.mean() *100)\n",
    "    # print(\"Recall:\",recall.mean() *100)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Create the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Display the confusion matrix\n",
    "    print(f\"Testing Confusion Matrix Depth {i}:\")\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique classes in the target variable 'Classification.1'\n",
    "class_names = y.unique().astype(str)\n",
    "\n",
    "# Visualize the Decision Tree with the corrected class names\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names=X.columns, class_names=class_names)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('ds.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde30178",
   "metadata": {},
   "source": [
    "### Displaying 1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff90daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = [\"P.S.\", 'U.S.'])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.savefig('Decision Tree CM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10900e65",
   "metadata": {},
   "source": [
    "### Evaluation Metric #2: Precision, Recall, and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5618398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'y_test' and 'y_pred' are the true labels and predicted labels respectively\n",
    "\n",
    "# Generate a classification report with precision, recall, F1-score, support, and averaging options\n",
    "report = classification_report(y_test, y_pred, target_names=['P.S.', 'U.S.'], output_dict=True)\n",
    "\n",
    "# Create a DataFrame from the classification report data\n",
    "import pandas as pd\n",
    "classification_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Display the classification report DataFrame\n",
    "print(classification_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8d3f4",
   "metadata": {},
   "source": [
    "## Random Forest Model\n",
    "### Created by: Brayan Gutierrez\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, classification_report, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import graphviz\n",
    "import random\n",
    "from scipy.stats import randint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fecaf39",
   "metadata": {},
   "source": [
    "### Data Reading and Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Dataset\n",
    "ground_water = pd.read_csv(\"ground_water_quality_2022_post.csv\")\n",
    "ground_water_df = pd.DataFrame(ground_water)\n",
    "ground_water_df = ground_water_df.dropna()\n",
    "\n",
    "ground_water_df = ground_water_df.rename(columns = {'NO3 ': 'NO3'})\n",
    "ground_water_df = ground_water_df.rename(columns = {'RSC  meq  / L': 'RSC'})\n",
    "numeric = ground_water_df.select_dtypes(include=['number']).columns\n",
    "nonnumeric = ground_water_df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Outlier Treatment\n",
    "for num in numeric:\n",
    "    Q1 = ground_water_df[num].quantile(0.25)\n",
    "    Q3 = ground_water_df[num].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    whisker_width = 1.5\n",
    "    lower_whisker = Q1 -(whisker_width*IQR)\n",
    "    upper_whisker = Q3 + (whisker_width*IQR)\n",
    "    ground_water_df[num]=np.where(ground_water_df[num]>upper_whisker,upper_whisker,np.where(ground_water_df[num]<lower_whisker,lower_whisker,ground_water_df[num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed7a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Chosen Feature to Dataframe\n",
    "chosen = ['RSC', 'SAR', 'Na', 'E.C', 'TDS', 'HCO3', 'pH', 'mandal', 'village', 'Classification.1']\n",
    "working_gw_df = ground_water_df[chosen]\n",
    "working_gw_df = working_gw_df.replace('MR', 'U.S.')\n",
    "\n",
    "# One-hot encode 'mandal' and 'village' columns separately\n",
    "mandal_dummies = pd.get_dummies(working_gw_df['mandal'], prefix='mandal')\n",
    "village_dummies = pd.get_dummies(working_gw_df['village'], prefix='village')\n",
    "\n",
    "# Concatenate the encoded columns with the original DataFrame\n",
    "working_gw_df_encoded = pd.concat([working_gw_df.drop(['mandal', 'village'], axis=1), mandal_dummies, village_dummies], axis=1)\n",
    "working_gw_df_encoded = working_gw_df_encoded.replace('MR', 'U.S.')\n",
    "\n",
    "# Display the modified DataFrame\n",
    "working_gw_df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267bb9de",
   "metadata": {},
   "source": [
    "### Random Forest Algorithm Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a69fa9",
   "metadata": {},
   "source": [
    "#### 1. Cross Validating Best Hyperparameters all Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20)}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(random_state = 10)\n",
    "\n",
    "# Use random search to find the best hyperparameters\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "\n",
    "# Fit the random search object to the data\n",
    "rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa42258",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "# Create a variable for the best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:',  rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e634fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators = rand_search.best_params_['n_estimators'], max_depth = rand_search.best_params_['max_depth'], random_state = 10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68098407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plot_tree(tree, feature_names=X_train.columns, class_names=['P.S.', 'U.S.'], filled=True, max_depth=4)\n",
    "    \n",
    "    if i == 1:\n",
    "        plt.savefig('All Feature CV.png')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb35406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize =  (10,5))\n",
    "sns.set(font_scale = 1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws = {'size':10}, cmap = plt.cm.Greens, linewidths = 0.2)\n",
    "\n",
    "class_names = ['P.S.', 'U.S.']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for All Features Random Forest Model (Cross Validation)')\n",
    "plt.savefig('Confusion Matrix for All Features Random Forest Model CV.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a7cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall, and F1 Score\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad6548",
   "metadata": {},
   "source": [
    "#### 2. Out of Bag Evaluation All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc95c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "# Splitting Data\n",
    "X = working_gw_df_encoded.drop('Classification.1', axis = 1)\n",
    "y = working_gw_df_encoded['Classification.1']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(oob_score = True, random_state = 10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Accuracy Test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plot_tree(tree, feature_names=X_train.columns, class_names=['P.S.', 'U.S.'], filled=True, max_depth=4)\n",
    "    \n",
    "    if i == 1:\n",
    "        plt.savefig('All Feature OOB.png')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c898e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize =  (10,5))\n",
    "sns.set(font_scale = 2)\n",
    "sns.heatmap(matrix, annot=True, annot_kws = {'size':10}, cmap = plt.cm.Greens, linewidths = 0.2)\n",
    "\n",
    "class_names = ['P.S.', 'U.S.']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for All Features Random Forest Model (OOB)')\n",
    "plt.savefig('Confusion Matrix for All Features Random Forest Model OOB.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall, and F1 Score\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96aeea7",
   "metadata": {},
   "source": [
    "#### 3. Cross Validating Best Hyperparameters Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4adb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20)}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(random_state = 10)\n",
    "\n",
    "# Use random search to find the best hyperparameters\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "\n",
    "# Fit the random search object to the data\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Create a variable for the best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:',  rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35982a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators = rand_search.best_params_['n_estimators'], max_depth = rand_search.best_params_['max_depth'], random_state = 10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Accuracy Test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plot_tree(tree, feature_names=X_train.columns, class_names=['P.S.', 'U.S.'], filled=True, max_depth=4)\n",
    "    \n",
    "    if i == 1:\n",
    "        plt.savefig('Numeric Features CV.png')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate feature importances\n",
    "importances = np.mean([tree.feature_importances_ for tree in best_rf.estimators_], axis=0)\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[sorted_indices]\n",
    "sorted_features = X_train.columns[sorted_indices]\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(sorted_importances)), sorted_importances, align='center')\n",
    "plt.xticks(range(len(sorted_importances)), sorted_features, rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importances CV')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Feature Importances CV.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd104a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize =  (10,5))\n",
    "sns.set(font_scale = 1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws = {'size':10}, cmap = plt.cm.Greens, linewidths = 0.2)\n",
    "\n",
    "class_names = ['P.S.', 'U.S.']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Numerical Features Random Forest Model (Cross Validated)')\n",
    "plt.savefig('Confusion Matrix for Numerical Features Random Forest Model CV.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44569df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall, and F1 Score\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc99d5",
   "metadata": {},
   "source": [
    "#### 4. Out of Bag Evaluation Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "chosen_numeric = ['RSC', 'SAR', 'Na', 'E.C', 'TDS', 'HCO3', 'pH', 'Classification.1']\n",
    "X = working_gw_df_encoded[chosen_numeric].drop('Classification.1', axis = 1)\n",
    "y = working_gw_df_encoded['Classification.1']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(oob_score = True, random_state = 10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plot_tree(tree, feature_names=X_train.columns, class_names=['P.S.', 'U.S.'], filled=True, max_depth=4)\n",
    "    \n",
    "    if i == 1:\n",
    "        plt.savefig('Numeric Features OOB.png')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14023412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[sorted_indices]\n",
    "sorted_features = X_train.columns[sorted_indices]\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(sorted_importances)), sorted_importances, align='center')\n",
    "plt.xticks(range(len(sorted_importances)), sorted_features, rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importances OOB')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Feature Importances OOB.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize =  (10,5))\n",
    "sns.set(font_scale = 1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws = {'size':10}, cmap = plt.cm.Greens, linewidths = 0.2)\n",
    "\n",
    "class_names = ['P.S.', 'U.S.']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Numerical Features Random Forest Model (OOB)')\n",
    "plt.savefig('Confusion Matrix for Numerical Features Random Forest Model OOB.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53712d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall, and F1 Score\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
